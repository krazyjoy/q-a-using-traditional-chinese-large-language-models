{
  "best_metric": 0.9939398169517517,
  "best_model_checkpoint": "./lora-alpaca/checkpoint-2600",
  "epoch": 9.401214926236621,
  "global_step": 2600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04,
      "learning_rate": 8.000000000000001e-06,
      "loss": 2.3284,
      "step": 10
    },
    {
      "epoch": 0.07,
      "learning_rate": 1.8e-05,
      "loss": 2.2735,
      "step": 20
    },
    {
      "epoch": 0.11,
      "learning_rate": 2.8000000000000003e-05,
      "loss": 2.1899,
      "step": 30
    },
    {
      "epoch": 0.14,
      "learning_rate": 3.8e-05,
      "loss": 2.06,
      "step": 40
    },
    {
      "epoch": 0.18,
      "learning_rate": 4.8e-05,
      "loss": 1.7918,
      "step": 50
    },
    {
      "epoch": 0.22,
      "learning_rate": 5.8e-05,
      "loss": 1.4784,
      "step": 60
    },
    {
      "epoch": 0.25,
      "learning_rate": 6.800000000000001e-05,
      "loss": 1.3816,
      "step": 70
    },
    {
      "epoch": 0.29,
      "learning_rate": 7.800000000000001e-05,
      "loss": 1.3344,
      "step": 80
    },
    {
      "epoch": 0.33,
      "learning_rate": 8.800000000000001e-05,
      "loss": 1.2779,
      "step": 90
    },
    {
      "epoch": 0.36,
      "learning_rate": 9.8e-05,
      "loss": 1.2446,
      "step": 100
    },
    {
      "epoch": 0.4,
      "learning_rate": 9.969924812030076e-05,
      "loss": 1.2253,
      "step": 110
    },
    {
      "epoch": 0.43,
      "learning_rate": 9.93233082706767e-05,
      "loss": 1.2085,
      "step": 120
    },
    {
      "epoch": 0.47,
      "learning_rate": 9.894736842105263e-05,
      "loss": 1.2034,
      "step": 130
    },
    {
      "epoch": 0.51,
      "learning_rate": 9.857142857142858e-05,
      "loss": 1.1967,
      "step": 140
    },
    {
      "epoch": 0.54,
      "learning_rate": 9.819548872180451e-05,
      "loss": 1.1848,
      "step": 150
    },
    {
      "epoch": 0.58,
      "learning_rate": 9.781954887218046e-05,
      "loss": 1.1801,
      "step": 160
    },
    {
      "epoch": 0.61,
      "learning_rate": 9.74436090225564e-05,
      "loss": 1.1695,
      "step": 170
    },
    {
      "epoch": 0.65,
      "learning_rate": 9.706766917293234e-05,
      "loss": 1.1575,
      "step": 180
    },
    {
      "epoch": 0.69,
      "learning_rate": 9.669172932330828e-05,
      "loss": 1.157,
      "step": 190
    },
    {
      "epoch": 0.72,
      "learning_rate": 9.631578947368421e-05,
      "loss": 1.1448,
      "step": 200
    },
    {
      "epoch": 0.72,
      "eval_loss": 1.2130173444747925,
      "eval_runtime": 18.9432,
      "eval_samples_per_second": 52.789,
      "eval_steps_per_second": 0.686,
      "step": 200
    },
    {
      "epoch": 0.76,
      "learning_rate": 9.593984962406016e-05,
      "loss": 1.1454,
      "step": 210
    },
    {
      "epoch": 0.8,
      "learning_rate": 9.55639097744361e-05,
      "loss": 1.1165,
      "step": 220
    },
    {
      "epoch": 0.83,
      "learning_rate": 9.518796992481204e-05,
      "loss": 1.1088,
      "step": 230
    },
    {
      "epoch": 0.87,
      "learning_rate": 9.481203007518797e-05,
      "loss": 1.0966,
      "step": 240
    },
    {
      "epoch": 0.9,
      "learning_rate": 9.44360902255639e-05,
      "loss": 1.1028,
      "step": 250
    },
    {
      "epoch": 0.94,
      "learning_rate": 9.406015037593985e-05,
      "loss": 1.089,
      "step": 260
    },
    {
      "epoch": 0.98,
      "learning_rate": 9.36842105263158e-05,
      "loss": 1.0895,
      "step": 270
    },
    {
      "epoch": 1.01,
      "learning_rate": 9.330827067669174e-05,
      "loss": 1.1105,
      "step": 280
    },
    {
      "epoch": 1.05,
      "learning_rate": 9.293233082706767e-05,
      "loss": 1.0818,
      "step": 290
    },
    {
      "epoch": 1.08,
      "learning_rate": 9.255639097744362e-05,
      "loss": 1.0863,
      "step": 300
    },
    {
      "epoch": 1.12,
      "learning_rate": 9.218045112781955e-05,
      "loss": 1.0774,
      "step": 310
    },
    {
      "epoch": 1.16,
      "learning_rate": 9.18045112781955e-05,
      "loss": 1.0698,
      "step": 320
    },
    {
      "epoch": 1.19,
      "learning_rate": 9.142857142857143e-05,
      "loss": 1.07,
      "step": 330
    },
    {
      "epoch": 1.23,
      "learning_rate": 9.105263157894738e-05,
      "loss": 1.0659,
      "step": 340
    },
    {
      "epoch": 1.27,
      "learning_rate": 9.067669172932331e-05,
      "loss": 1.0578,
      "step": 350
    },
    {
      "epoch": 1.3,
      "learning_rate": 9.030075187969925e-05,
      "loss": 1.0598,
      "step": 360
    },
    {
      "epoch": 1.34,
      "learning_rate": 8.99248120300752e-05,
      "loss": 1.0501,
      "step": 370
    },
    {
      "epoch": 1.37,
      "learning_rate": 8.954887218045113e-05,
      "loss": 1.0481,
      "step": 380
    },
    {
      "epoch": 1.41,
      "learning_rate": 8.917293233082708e-05,
      "loss": 1.0472,
      "step": 390
    },
    {
      "epoch": 1.45,
      "learning_rate": 8.879699248120301e-05,
      "loss": 1.0574,
      "step": 400
    },
    {
      "epoch": 1.45,
      "eval_loss": 1.1291782855987549,
      "eval_runtime": 18.9266,
      "eval_samples_per_second": 52.836,
      "eval_steps_per_second": 0.687,
      "step": 400
    },
    {
      "epoch": 1.48,
      "learning_rate": 8.842105263157894e-05,
      "loss": 1.0498,
      "step": 410
    },
    {
      "epoch": 1.52,
      "learning_rate": 8.804511278195489e-05,
      "loss": 1.0483,
      "step": 420
    },
    {
      "epoch": 1.55,
      "learning_rate": 8.766917293233084e-05,
      "loss": 1.0447,
      "step": 430
    },
    {
      "epoch": 1.59,
      "learning_rate": 8.729323308270677e-05,
      "loss": 1.0361,
      "step": 440
    },
    {
      "epoch": 1.63,
      "learning_rate": 8.691729323308271e-05,
      "loss": 1.037,
      "step": 450
    },
    {
      "epoch": 1.66,
      "learning_rate": 8.654135338345864e-05,
      "loss": 1.036,
      "step": 460
    },
    {
      "epoch": 1.7,
      "learning_rate": 8.616541353383459e-05,
      "loss": 1.0394,
      "step": 470
    },
    {
      "epoch": 1.74,
      "learning_rate": 8.578947368421054e-05,
      "loss": 1.0311,
      "step": 480
    },
    {
      "epoch": 1.77,
      "learning_rate": 8.541353383458647e-05,
      "loss": 1.0296,
      "step": 490
    },
    {
      "epoch": 1.81,
      "learning_rate": 8.50375939849624e-05,
      "loss": 1.0281,
      "step": 500
    },
    {
      "epoch": 1.84,
      "learning_rate": 8.466165413533835e-05,
      "loss": 1.0308,
      "step": 510
    },
    {
      "epoch": 1.88,
      "learning_rate": 8.428571428571429e-05,
      "loss": 1.0282,
      "step": 520
    },
    {
      "epoch": 1.92,
      "learning_rate": 8.390977443609023e-05,
      "loss": 1.0249,
      "step": 530
    },
    {
      "epoch": 1.95,
      "learning_rate": 8.353383458646617e-05,
      "loss": 1.0232,
      "step": 540
    },
    {
      "epoch": 1.99,
      "learning_rate": 8.315789473684212e-05,
      "loss": 1.0221,
      "step": 550
    },
    {
      "epoch": 2.02,
      "learning_rate": 8.278195488721805e-05,
      "loss": 1.0127,
      "step": 560
    },
    {
      "epoch": 2.06,
      "learning_rate": 8.240601503759398e-05,
      "loss": 1.0108,
      "step": 570
    },
    {
      "epoch": 2.1,
      "learning_rate": 8.203007518796992e-05,
      "loss": 1.0128,
      "step": 580
    },
    {
      "epoch": 2.13,
      "learning_rate": 8.165413533834588e-05,
      "loss": 1.0005,
      "step": 590
    },
    {
      "epoch": 2.17,
      "learning_rate": 8.127819548872181e-05,
      "loss": 1.0109,
      "step": 600
    },
    {
      "epoch": 2.17,
      "eval_loss": 1.0931084156036377,
      "eval_runtime": 18.9064,
      "eval_samples_per_second": 52.892,
      "eval_steps_per_second": 0.688,
      "step": 600
    },
    {
      "epoch": 2.21,
      "learning_rate": 8.090225563909775e-05,
      "loss": 1.0125,
      "step": 610
    },
    {
      "epoch": 2.24,
      "learning_rate": 8.052631578947368e-05,
      "loss": 1.006,
      "step": 620
    },
    {
      "epoch": 2.28,
      "learning_rate": 8.015037593984963e-05,
      "loss": 1.0075,
      "step": 630
    },
    {
      "epoch": 2.31,
      "learning_rate": 7.977443609022558e-05,
      "loss": 0.9985,
      "step": 640
    },
    {
      "epoch": 2.35,
      "learning_rate": 7.939849624060151e-05,
      "loss": 0.9957,
      "step": 650
    },
    {
      "epoch": 2.39,
      "learning_rate": 7.902255639097744e-05,
      "loss": 1.0012,
      "step": 660
    },
    {
      "epoch": 2.42,
      "learning_rate": 7.864661654135339e-05,
      "loss": 0.9958,
      "step": 670
    },
    {
      "epoch": 2.46,
      "learning_rate": 7.827067669172932e-05,
      "loss": 1.001,
      "step": 680
    },
    {
      "epoch": 2.49,
      "learning_rate": 7.789473684210526e-05,
      "loss": 0.9982,
      "step": 690
    },
    {
      "epoch": 2.53,
      "learning_rate": 7.75187969924812e-05,
      "loss": 1.0014,
      "step": 700
    },
    {
      "epoch": 2.57,
      "learning_rate": 7.714285714285715e-05,
      "loss": 0.993,
      "step": 710
    },
    {
      "epoch": 2.6,
      "learning_rate": 7.676691729323309e-05,
      "loss": 0.9933,
      "step": 720
    },
    {
      "epoch": 2.64,
      "learning_rate": 7.639097744360902e-05,
      "loss": 0.9851,
      "step": 730
    },
    {
      "epoch": 2.68,
      "learning_rate": 7.601503759398496e-05,
      "loss": 0.9875,
      "step": 740
    },
    {
      "epoch": 2.71,
      "learning_rate": 7.56390977443609e-05,
      "loss": 0.9853,
      "step": 750
    },
    {
      "epoch": 2.75,
      "learning_rate": 7.526315789473685e-05,
      "loss": 0.9881,
      "step": 760
    },
    {
      "epoch": 2.78,
      "learning_rate": 7.488721804511278e-05,
      "loss": 0.978,
      "step": 770
    },
    {
      "epoch": 2.82,
      "learning_rate": 7.451127819548872e-05,
      "loss": 0.9853,
      "step": 780
    },
    {
      "epoch": 2.86,
      "learning_rate": 7.413533834586467e-05,
      "loss": 0.975,
      "step": 790
    },
    {
      "epoch": 2.89,
      "learning_rate": 7.37593984962406e-05,
      "loss": 0.9856,
      "step": 800
    },
    {
      "epoch": 2.89,
      "eval_loss": 1.0659890174865723,
      "eval_runtime": 18.9165,
      "eval_samples_per_second": 52.864,
      "eval_steps_per_second": 0.687,
      "step": 800
    },
    {
      "epoch": 2.93,
      "learning_rate": 7.338345864661655e-05,
      "loss": 0.9775,
      "step": 810
    },
    {
      "epoch": 2.96,
      "learning_rate": 7.300751879699248e-05,
      "loss": 0.9771,
      "step": 820
    },
    {
      "epoch": 3.0,
      "learning_rate": 7.263157894736843e-05,
      "loss": 0.9646,
      "step": 830
    },
    {
      "epoch": 3.04,
      "learning_rate": 7.225563909774436e-05,
      "loss": 0.983,
      "step": 840
    },
    {
      "epoch": 3.07,
      "learning_rate": 7.18796992481203e-05,
      "loss": 0.9732,
      "step": 850
    },
    {
      "epoch": 3.11,
      "learning_rate": 7.150375939849624e-05,
      "loss": 0.9665,
      "step": 860
    },
    {
      "epoch": 3.15,
      "learning_rate": 7.112781954887219e-05,
      "loss": 0.9703,
      "step": 870
    },
    {
      "epoch": 3.18,
      "learning_rate": 7.075187969924813e-05,
      "loss": 0.9702,
      "step": 880
    },
    {
      "epoch": 3.22,
      "learning_rate": 7.037593984962406e-05,
      "loss": 0.9734,
      "step": 890
    },
    {
      "epoch": 3.25,
      "learning_rate": 7e-05,
      "loss": 0.9777,
      "step": 900
    },
    {
      "epoch": 3.29,
      "learning_rate": 6.962406015037594e-05,
      "loss": 0.9758,
      "step": 910
    },
    {
      "epoch": 3.33,
      "learning_rate": 6.924812030075189e-05,
      "loss": 0.9628,
      "step": 920
    },
    {
      "epoch": 3.36,
      "learning_rate": 6.887218045112782e-05,
      "loss": 0.9638,
      "step": 930
    },
    {
      "epoch": 3.4,
      "learning_rate": 6.849624060150376e-05,
      "loss": 0.972,
      "step": 940
    },
    {
      "epoch": 3.44,
      "learning_rate": 6.81203007518797e-05,
      "loss": 0.9589,
      "step": 950
    },
    {
      "epoch": 3.47,
      "learning_rate": 6.774436090225564e-05,
      "loss": 0.9587,
      "step": 960
    },
    {
      "epoch": 3.51,
      "learning_rate": 6.736842105263159e-05,
      "loss": 0.9674,
      "step": 970
    },
    {
      "epoch": 3.54,
      "learning_rate": 6.699248120300752e-05,
      "loss": 0.956,
      "step": 980
    },
    {
      "epoch": 3.58,
      "learning_rate": 6.661654135338347e-05,
      "loss": 0.9629,
      "step": 990
    },
    {
      "epoch": 3.62,
      "learning_rate": 6.62406015037594e-05,
      "loss": 0.9605,
      "step": 1000
    },
    {
      "epoch": 3.62,
      "eval_loss": 1.0478814840316772,
      "eval_runtime": 18.9181,
      "eval_samples_per_second": 52.859,
      "eval_steps_per_second": 0.687,
      "step": 1000
    },
    {
      "epoch": 3.65,
      "learning_rate": 6.586466165413534e-05,
      "loss": 0.9645,
      "step": 1010
    },
    {
      "epoch": 3.69,
      "learning_rate": 6.548872180451128e-05,
      "loss": 0.9549,
      "step": 1020
    },
    {
      "epoch": 3.72,
      "learning_rate": 6.511278195488723e-05,
      "loss": 0.95,
      "step": 1030
    },
    {
      "epoch": 3.76,
      "learning_rate": 6.473684210526316e-05,
      "loss": 0.9569,
      "step": 1040
    },
    {
      "epoch": 3.8,
      "learning_rate": 6.43609022556391e-05,
      "loss": 0.9551,
      "step": 1050
    },
    {
      "epoch": 3.83,
      "learning_rate": 6.398496240601503e-05,
      "loss": 0.958,
      "step": 1060
    },
    {
      "epoch": 3.87,
      "learning_rate": 6.360902255639098e-05,
      "loss": 0.9549,
      "step": 1070
    },
    {
      "epoch": 3.91,
      "learning_rate": 6.323308270676693e-05,
      "loss": 0.952,
      "step": 1080
    },
    {
      "epoch": 3.94,
      "learning_rate": 6.285714285714286e-05,
      "loss": 0.9567,
      "step": 1090
    },
    {
      "epoch": 3.98,
      "learning_rate": 6.24812030075188e-05,
      "loss": 0.9569,
      "step": 1100
    },
    {
      "epoch": 4.01,
      "learning_rate": 6.210526315789474e-05,
      "loss": 0.9635,
      "step": 1110
    },
    {
      "epoch": 4.05,
      "learning_rate": 6.172932330827068e-05,
      "loss": 0.9485,
      "step": 1120
    },
    {
      "epoch": 4.09,
      "learning_rate": 6.135338345864662e-05,
      "loss": 0.9476,
      "step": 1130
    },
    {
      "epoch": 4.12,
      "learning_rate": 6.097744360902256e-05,
      "loss": 0.9505,
      "step": 1140
    },
    {
      "epoch": 4.16,
      "learning_rate": 6.0601503759398506e-05,
      "loss": 0.946,
      "step": 1150
    },
    {
      "epoch": 4.19,
      "learning_rate": 6.022556390977444e-05,
      "loss": 0.9473,
      "step": 1160
    },
    {
      "epoch": 4.23,
      "learning_rate": 5.984962406015038e-05,
      "loss": 0.9546,
      "step": 1170
    },
    {
      "epoch": 4.27,
      "learning_rate": 5.9473684210526315e-05,
      "loss": 0.9434,
      "step": 1180
    },
    {
      "epoch": 4.3,
      "learning_rate": 5.909774436090226e-05,
      "loss": 0.9421,
      "step": 1190
    },
    {
      "epoch": 4.34,
      "learning_rate": 5.87218045112782e-05,
      "loss": 0.9379,
      "step": 1200
    },
    {
      "epoch": 4.34,
      "eval_loss": 1.033934235572815,
      "eval_runtime": 18.9213,
      "eval_samples_per_second": 52.851,
      "eval_steps_per_second": 0.687,
      "step": 1200
    },
    {
      "epoch": 4.38,
      "learning_rate": 5.834586466165414e-05,
      "loss": 0.9433,
      "step": 1210
    },
    {
      "epoch": 4.41,
      "learning_rate": 5.796992481203008e-05,
      "loss": 0.9475,
      "step": 1220
    },
    {
      "epoch": 4.45,
      "learning_rate": 5.7593984962406025e-05,
      "loss": 0.936,
      "step": 1230
    },
    {
      "epoch": 4.48,
      "learning_rate": 5.721804511278196e-05,
      "loss": 0.934,
      "step": 1240
    },
    {
      "epoch": 4.52,
      "learning_rate": 5.68421052631579e-05,
      "loss": 0.9381,
      "step": 1250
    },
    {
      "epoch": 4.56,
      "learning_rate": 5.6466165413533834e-05,
      "loss": 0.933,
      "step": 1260
    },
    {
      "epoch": 4.59,
      "learning_rate": 5.609022556390978e-05,
      "loss": 0.9297,
      "step": 1270
    },
    {
      "epoch": 4.63,
      "learning_rate": 5.571428571428572e-05,
      "loss": 0.9431,
      "step": 1280
    },
    {
      "epoch": 4.66,
      "learning_rate": 5.5338345864661656e-05,
      "loss": 0.9433,
      "step": 1290
    },
    {
      "epoch": 4.7,
      "learning_rate": 5.496240601503759e-05,
      "loss": 0.9269,
      "step": 1300
    },
    {
      "epoch": 4.74,
      "learning_rate": 5.4586466165413544e-05,
      "loss": 0.9344,
      "step": 1310
    },
    {
      "epoch": 4.77,
      "learning_rate": 5.421052631578948e-05,
      "loss": 0.9327,
      "step": 1320
    },
    {
      "epoch": 4.81,
      "learning_rate": 5.383458646616541e-05,
      "loss": 0.9403,
      "step": 1330
    },
    {
      "epoch": 4.85,
      "learning_rate": 5.345864661654135e-05,
      "loss": 0.9271,
      "step": 1340
    },
    {
      "epoch": 4.88,
      "learning_rate": 5.30827067669173e-05,
      "loss": 0.9333,
      "step": 1350
    },
    {
      "epoch": 4.92,
      "learning_rate": 5.2706766917293234e-05,
      "loss": 0.9345,
      "step": 1360
    },
    {
      "epoch": 4.95,
      "learning_rate": 5.2330827067669175e-05,
      "loss": 0.9302,
      "step": 1370
    },
    {
      "epoch": 4.99,
      "learning_rate": 5.195488721804511e-05,
      "loss": 0.9321,
      "step": 1380
    },
    {
      "epoch": 5.03,
      "learning_rate": 5.157894736842106e-05,
      "loss": 0.9253,
      "step": 1390
    },
    {
      "epoch": 5.06,
      "learning_rate": 5.1203007518797e-05,
      "loss": 0.9237,
      "step": 1400
    },
    {
      "epoch": 5.06,
      "eval_loss": 1.023909330368042,
      "eval_runtime": 18.9023,
      "eval_samples_per_second": 52.904,
      "eval_steps_per_second": 0.688,
      "step": 1400
    },
    {
      "epoch": 5.1,
      "learning_rate": 5.082706766917293e-05,
      "loss": 0.9294,
      "step": 1410
    },
    {
      "epoch": 5.13,
      "learning_rate": 5.045112781954887e-05,
      "loss": 0.9291,
      "step": 1420
    },
    {
      "epoch": 5.17,
      "learning_rate": 5.007518796992482e-05,
      "loss": 0.9316,
      "step": 1430
    },
    {
      "epoch": 5.21,
      "learning_rate": 4.9699248120300754e-05,
      "loss": 0.9205,
      "step": 1440
    },
    {
      "epoch": 5.24,
      "learning_rate": 4.9323308270676694e-05,
      "loss": 0.9266,
      "step": 1450
    },
    {
      "epoch": 5.28,
      "learning_rate": 4.8947368421052635e-05,
      "loss": 0.9262,
      "step": 1460
    },
    {
      "epoch": 5.32,
      "learning_rate": 4.8571428571428576e-05,
      "loss": 0.9221,
      "step": 1470
    },
    {
      "epoch": 5.35,
      "learning_rate": 4.819548872180452e-05,
      "loss": 0.921,
      "step": 1480
    },
    {
      "epoch": 5.39,
      "learning_rate": 4.781954887218045e-05,
      "loss": 0.923,
      "step": 1490
    },
    {
      "epoch": 5.42,
      "learning_rate": 4.74436090225564e-05,
      "loss": 0.9243,
      "step": 1500
    },
    {
      "epoch": 5.46,
      "learning_rate": 4.706766917293233e-05,
      "loss": 0.9179,
      "step": 1510
    },
    {
      "epoch": 5.5,
      "learning_rate": 4.669172932330827e-05,
      "loss": 0.9201,
      "step": 1520
    },
    {
      "epoch": 5.53,
      "learning_rate": 4.6315789473684214e-05,
      "loss": 0.9248,
      "step": 1530
    },
    {
      "epoch": 5.57,
      "learning_rate": 4.5939849624060154e-05,
      "loss": 0.9221,
      "step": 1540
    },
    {
      "epoch": 5.6,
      "learning_rate": 4.5563909774436095e-05,
      "loss": 0.9158,
      "step": 1550
    },
    {
      "epoch": 5.64,
      "learning_rate": 4.5187969924812036e-05,
      "loss": 0.9215,
      "step": 1560
    },
    {
      "epoch": 5.68,
      "learning_rate": 4.481203007518797e-05,
      "loss": 0.921,
      "step": 1570
    },
    {
      "epoch": 5.71,
      "learning_rate": 4.443609022556392e-05,
      "loss": 0.9258,
      "step": 1580
    },
    {
      "epoch": 5.75,
      "learning_rate": 4.406015037593985e-05,
      "loss": 0.918,
      "step": 1590
    },
    {
      "epoch": 5.79,
      "learning_rate": 4.368421052631579e-05,
      "loss": 0.9178,
      "step": 1600
    },
    {
      "epoch": 5.79,
      "eval_loss": 1.0146048069000244,
      "eval_runtime": 18.9183,
      "eval_samples_per_second": 52.859,
      "eval_steps_per_second": 0.687,
      "step": 1600
    },
    {
      "epoch": 5.82,
      "learning_rate": 4.330827067669173e-05,
      "loss": 0.9164,
      "step": 1610
    },
    {
      "epoch": 5.86,
      "learning_rate": 4.2932330827067674e-05,
      "loss": 0.9147,
      "step": 1620
    },
    {
      "epoch": 5.89,
      "learning_rate": 4.255639097744361e-05,
      "loss": 0.9131,
      "step": 1630
    },
    {
      "epoch": 5.93,
      "learning_rate": 4.2180451127819555e-05,
      "loss": 0.9159,
      "step": 1640
    },
    {
      "epoch": 5.97,
      "learning_rate": 4.180451127819549e-05,
      "loss": 0.9051,
      "step": 1650
    },
    {
      "epoch": 6.0,
      "learning_rate": 4.1428571428571437e-05,
      "loss": 0.8996,
      "step": 1660
    },
    {
      "epoch": 6.04,
      "learning_rate": 4.105263157894737e-05,
      "loss": 0.9155,
      "step": 1670
    },
    {
      "epoch": 6.07,
      "learning_rate": 4.067669172932331e-05,
      "loss": 0.9121,
      "step": 1680
    },
    {
      "epoch": 6.11,
      "learning_rate": 4.030075187969925e-05,
      "loss": 0.9166,
      "step": 1690
    },
    {
      "epoch": 6.15,
      "learning_rate": 3.9924812030075186e-05,
      "loss": 0.9053,
      "step": 1700
    },
    {
      "epoch": 6.18,
      "learning_rate": 3.954887218045113e-05,
      "loss": 0.9185,
      "step": 1710
    },
    {
      "epoch": 6.22,
      "learning_rate": 3.917293233082707e-05,
      "loss": 0.9084,
      "step": 1720
    },
    {
      "epoch": 6.26,
      "learning_rate": 3.879699248120301e-05,
      "loss": 0.9108,
      "step": 1730
    },
    {
      "epoch": 6.29,
      "learning_rate": 3.842105263157895e-05,
      "loss": 0.9049,
      "step": 1740
    },
    {
      "epoch": 6.33,
      "learning_rate": 3.804511278195489e-05,
      "loss": 0.9144,
      "step": 1750
    },
    {
      "epoch": 6.36,
      "learning_rate": 3.7669172932330824e-05,
      "loss": 0.9149,
      "step": 1760
    },
    {
      "epoch": 6.4,
      "learning_rate": 3.729323308270677e-05,
      "loss": 0.916,
      "step": 1770
    },
    {
      "epoch": 6.44,
      "learning_rate": 3.6917293233082705e-05,
      "loss": 0.8985,
      "step": 1780
    },
    {
      "epoch": 6.47,
      "learning_rate": 3.6541353383458646e-05,
      "loss": 0.9037,
      "step": 1790
    },
    {
      "epoch": 6.51,
      "learning_rate": 3.616541353383459e-05,
      "loss": 0.9081,
      "step": 1800
    },
    {
      "epoch": 6.51,
      "eval_loss": 1.0090749263763428,
      "eval_runtime": 18.9098,
      "eval_samples_per_second": 52.883,
      "eval_steps_per_second": 0.687,
      "step": 1800
    },
    {
      "epoch": 6.54,
      "learning_rate": 3.578947368421053e-05,
      "loss": 0.9101,
      "step": 1810
    },
    {
      "epoch": 6.58,
      "learning_rate": 3.541353383458647e-05,
      "loss": 0.9116,
      "step": 1820
    },
    {
      "epoch": 6.62,
      "learning_rate": 3.503759398496241e-05,
      "loss": 0.9093,
      "step": 1830
    },
    {
      "epoch": 6.65,
      "learning_rate": 3.466165413533834e-05,
      "loss": 0.9072,
      "step": 1840
    },
    {
      "epoch": 6.69,
      "learning_rate": 3.428571428571429e-05,
      "loss": 0.9032,
      "step": 1850
    },
    {
      "epoch": 6.73,
      "learning_rate": 3.3909774436090224e-05,
      "loss": 0.9083,
      "step": 1860
    },
    {
      "epoch": 6.76,
      "learning_rate": 3.3533834586466165e-05,
      "loss": 0.9145,
      "step": 1870
    },
    {
      "epoch": 6.8,
      "learning_rate": 3.3157894736842106e-05,
      "loss": 0.9079,
      "step": 1880
    },
    {
      "epoch": 6.83,
      "learning_rate": 3.278195488721805e-05,
      "loss": 0.895,
      "step": 1890
    },
    {
      "epoch": 6.87,
      "learning_rate": 3.240601503759399e-05,
      "loss": 0.9146,
      "step": 1900
    },
    {
      "epoch": 6.91,
      "learning_rate": 3.203007518796993e-05,
      "loss": 0.9137,
      "step": 1910
    },
    {
      "epoch": 6.94,
      "learning_rate": 3.165413533834586e-05,
      "loss": 0.8998,
      "step": 1920
    },
    {
      "epoch": 6.98,
      "learning_rate": 3.127819548872181e-05,
      "loss": 0.9017,
      "step": 1930
    },
    {
      "epoch": 7.01,
      "learning_rate": 3.0902255639097744e-05,
      "loss": 0.908,
      "step": 1940
    },
    {
      "epoch": 7.05,
      "learning_rate": 3.0526315789473684e-05,
      "loss": 0.9007,
      "step": 1950
    },
    {
      "epoch": 7.09,
      "learning_rate": 3.0150375939849622e-05,
      "loss": 0.8935,
      "step": 1960
    },
    {
      "epoch": 7.12,
      "learning_rate": 2.9774436090225566e-05,
      "loss": 0.9075,
      "step": 1970
    },
    {
      "epoch": 7.16,
      "learning_rate": 2.9398496240601503e-05,
      "loss": 0.9091,
      "step": 1980
    },
    {
      "epoch": 7.2,
      "learning_rate": 2.9022556390977444e-05,
      "loss": 0.8936,
      "step": 1990
    },
    {
      "epoch": 7.23,
      "learning_rate": 2.864661654135338e-05,
      "loss": 0.8996,
      "step": 2000
    },
    {
      "epoch": 7.23,
      "eval_loss": 1.003684163093567,
      "eval_runtime": 18.9037,
      "eval_samples_per_second": 52.9,
      "eval_steps_per_second": 0.688,
      "step": 2000
    },
    {
      "epoch": 7.27,
      "learning_rate": 2.8270676691729325e-05,
      "loss": 0.8973,
      "step": 2010
    },
    {
      "epoch": 7.3,
      "learning_rate": 2.7894736842105263e-05,
      "loss": 0.904,
      "step": 2020
    },
    {
      "epoch": 7.34,
      "learning_rate": 2.7518796992481204e-05,
      "loss": 0.8968,
      "step": 2030
    },
    {
      "epoch": 7.38,
      "learning_rate": 2.714285714285714e-05,
      "loss": 0.9029,
      "step": 2040
    },
    {
      "epoch": 7.41,
      "learning_rate": 2.6766917293233085e-05,
      "loss": 0.9013,
      "step": 2050
    },
    {
      "epoch": 7.45,
      "learning_rate": 2.6390977443609022e-05,
      "loss": 0.9021,
      "step": 2060
    },
    {
      "epoch": 7.48,
      "learning_rate": 2.6015037593984963e-05,
      "loss": 0.8962,
      "step": 2070
    },
    {
      "epoch": 7.52,
      "learning_rate": 2.56390977443609e-05,
      "loss": 0.8958,
      "step": 2080
    },
    {
      "epoch": 7.56,
      "learning_rate": 2.5263157894736845e-05,
      "loss": 0.899,
      "step": 2090
    },
    {
      "epoch": 7.59,
      "learning_rate": 2.4887218045112785e-05,
      "loss": 0.902,
      "step": 2100
    },
    {
      "epoch": 7.63,
      "learning_rate": 2.4511278195488723e-05,
      "loss": 0.8937,
      "step": 2110
    },
    {
      "epoch": 7.67,
      "learning_rate": 2.4135338345864664e-05,
      "loss": 0.8972,
      "step": 2120
    },
    {
      "epoch": 7.7,
      "learning_rate": 2.3759398496240604e-05,
      "loss": 0.8949,
      "step": 2130
    },
    {
      "epoch": 7.74,
      "learning_rate": 2.3383458646616545e-05,
      "loss": 0.8966,
      "step": 2140
    },
    {
      "epoch": 7.77,
      "learning_rate": 2.3007518796992482e-05,
      "loss": 0.8893,
      "step": 2150
    },
    {
      "epoch": 7.81,
      "learning_rate": 2.2631578947368423e-05,
      "loss": 0.8934,
      "step": 2160
    },
    {
      "epoch": 7.85,
      "learning_rate": 2.2255639097744364e-05,
      "loss": 0.8931,
      "step": 2170
    },
    {
      "epoch": 7.88,
      "learning_rate": 2.18796992481203e-05,
      "loss": 0.8969,
      "step": 2180
    },
    {
      "epoch": 7.92,
      "learning_rate": 2.1503759398496242e-05,
      "loss": 0.8899,
      "step": 2190
    },
    {
      "epoch": 7.95,
      "learning_rate": 2.1127819548872183e-05,
      "loss": 0.8899,
      "step": 2200
    },
    {
      "epoch": 7.95,
      "eval_loss": 0.9997496604919434,
      "eval_runtime": 18.9094,
      "eval_samples_per_second": 52.884,
      "eval_steps_per_second": 0.687,
      "step": 2200
    },
    {
      "epoch": 7.99,
      "learning_rate": 2.0751879699248124e-05,
      "loss": 0.8938,
      "step": 2210
    },
    {
      "epoch": 8.03,
      "learning_rate": 2.037593984962406e-05,
      "loss": 0.9074,
      "step": 2220
    },
    {
      "epoch": 8.06,
      "learning_rate": 2e-05,
      "loss": 0.8925,
      "step": 2230
    },
    {
      "epoch": 8.1,
      "learning_rate": 1.9624060150375942e-05,
      "loss": 0.8938,
      "step": 2240
    },
    {
      "epoch": 8.14,
      "learning_rate": 1.9248120300751883e-05,
      "loss": 0.8884,
      "step": 2250
    },
    {
      "epoch": 8.17,
      "learning_rate": 1.887218045112782e-05,
      "loss": 0.8893,
      "step": 2260
    },
    {
      "epoch": 8.21,
      "learning_rate": 1.849624060150376e-05,
      "loss": 0.9017,
      "step": 2270
    },
    {
      "epoch": 8.24,
      "learning_rate": 1.8120300751879702e-05,
      "loss": 0.8996,
      "step": 2280
    },
    {
      "epoch": 8.28,
      "learning_rate": 1.7744360902255643e-05,
      "loss": 0.8894,
      "step": 2290
    },
    {
      "epoch": 8.32,
      "learning_rate": 1.736842105263158e-05,
      "loss": 0.8936,
      "step": 2300
    },
    {
      "epoch": 8.35,
      "learning_rate": 1.699248120300752e-05,
      "loss": 0.8901,
      "step": 2310
    },
    {
      "epoch": 8.39,
      "learning_rate": 1.661654135338346e-05,
      "loss": 0.8863,
      "step": 2320
    },
    {
      "epoch": 8.42,
      "learning_rate": 1.62406015037594e-05,
      "loss": 0.8961,
      "step": 2330
    },
    {
      "epoch": 8.46,
      "learning_rate": 1.586466165413534e-05,
      "loss": 0.891,
      "step": 2340
    },
    {
      "epoch": 8.5,
      "learning_rate": 1.548872180451128e-05,
      "loss": 0.8912,
      "step": 2350
    },
    {
      "epoch": 8.53,
      "learning_rate": 1.511278195488722e-05,
      "loss": 0.8926,
      "step": 2360
    },
    {
      "epoch": 8.57,
      "learning_rate": 1.4736842105263157e-05,
      "loss": 0.8926,
      "step": 2370
    },
    {
      "epoch": 8.61,
      "learning_rate": 1.4360902255639098e-05,
      "loss": 0.8936,
      "step": 2380
    },
    {
      "epoch": 8.64,
      "learning_rate": 1.3984962406015037e-05,
      "loss": 0.8912,
      "step": 2390
    },
    {
      "epoch": 8.68,
      "learning_rate": 1.3609022556390977e-05,
      "loss": 0.8836,
      "step": 2400
    },
    {
      "epoch": 8.68,
      "eval_loss": 0.9961217641830444,
      "eval_runtime": 18.9081,
      "eval_samples_per_second": 52.887,
      "eval_steps_per_second": 0.688,
      "step": 2400
    },
    {
      "epoch": 8.71,
      "learning_rate": 1.3233082706766916e-05,
      "loss": 0.8928,
      "step": 2410
    },
    {
      "epoch": 8.75,
      "learning_rate": 1.2857142857142857e-05,
      "loss": 0.8909,
      "step": 2420
    },
    {
      "epoch": 8.79,
      "learning_rate": 1.2481203007518798e-05,
      "loss": 0.8875,
      "step": 2430
    },
    {
      "epoch": 8.82,
      "learning_rate": 1.2105263157894737e-05,
      "loss": 0.8897,
      "step": 2440
    },
    {
      "epoch": 8.86,
      "learning_rate": 1.1729323308270678e-05,
      "loss": 0.8942,
      "step": 2450
    },
    {
      "epoch": 8.89,
      "learning_rate": 1.1353383458646617e-05,
      "loss": 0.8973,
      "step": 2460
    },
    {
      "epoch": 8.93,
      "learning_rate": 1.0977443609022558e-05,
      "loss": 0.896,
      "step": 2470
    },
    {
      "epoch": 8.97,
      "learning_rate": 1.0601503759398497e-05,
      "loss": 0.8912,
      "step": 2480
    },
    {
      "epoch": 9.0,
      "learning_rate": 1.0225563909774437e-05,
      "loss": 0.8765,
      "step": 2490
    },
    {
      "epoch": 9.04,
      "learning_rate": 9.849624060150376e-06,
      "loss": 0.8801,
      "step": 2500
    },
    {
      "epoch": 9.08,
      "learning_rate": 9.473684210526317e-06,
      "loss": 0.8929,
      "step": 2510
    },
    {
      "epoch": 9.11,
      "learning_rate": 9.097744360902256e-06,
      "loss": 0.8894,
      "step": 2520
    },
    {
      "epoch": 9.15,
      "learning_rate": 8.721804511278197e-06,
      "loss": 0.8913,
      "step": 2530
    },
    {
      "epoch": 9.18,
      "learning_rate": 8.345864661654136e-06,
      "loss": 0.8891,
      "step": 2540
    },
    {
      "epoch": 9.22,
      "learning_rate": 7.969924812030077e-06,
      "loss": 0.8843,
      "step": 2550
    },
    {
      "epoch": 9.26,
      "learning_rate": 7.593984962406016e-06,
      "loss": 0.8862,
      "step": 2560
    },
    {
      "epoch": 9.29,
      "learning_rate": 7.218045112781956e-06,
      "loss": 0.8902,
      "step": 2570
    },
    {
      "epoch": 9.33,
      "learning_rate": 6.842105263157896e-06,
      "loss": 0.8961,
      "step": 2580
    },
    {
      "epoch": 9.37,
      "learning_rate": 6.4661654135338356e-06,
      "loss": 0.8929,
      "step": 2590
    },
    {
      "epoch": 9.4,
      "learning_rate": 6.090225563909775e-06,
      "loss": 0.8915,
      "step": 2600
    },
    {
      "epoch": 9.4,
      "eval_loss": 0.9939398169517517,
      "eval_runtime": 18.9195,
      "eval_samples_per_second": 52.855,
      "eval_steps_per_second": 0.687,
      "step": 2600
    }
  ],
  "max_steps": 2760,
  "num_train_epochs": 10,
  "total_flos": 5.408727237262311e+18,
  "trial_name": null,
  "trial_params": null
}
